{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrduarte/Documents/FCT/samsung/jupyter-env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-02-18 12:44:46.328680: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1739882686.394971   52005 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1739882686.413570   52005 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-18 12:44:46.524893: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BertTokenizer, BertConfig , BertModel, DistilBertModel, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, pipeline\n",
    "from datasets import Dataset\n",
    "\n",
    "# Setup logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "# Set the device and load the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agrument Analyses\n",
    "This part load dataset will be use to train and test BERT\n",
    "\n",
    "This dataset was also created by our `llama_week_labeling.py` script.\n",
    "\n",
    "We use dataset from [`US Election 2020 - Presidential Debates`](https://www.kaggle.com/datasets/headsortails/us-election-2020-presidential-debates) collection and start to create the labels:\n",
    "- `Restatement`: The second statement restates or reinforces the first.\n",
    "- `Counterargument`: The second statement opposes the first.\n",
    "- `Neutral`: No clear relationship between the statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 745 entries, 0 to 744\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   speaker1    745 non-null    object\n",
      " 1   statement1  745 non-null    object\n",
      " 2   speaker2    745 non-null    object\n",
      " 3   statement2  745 non-null    object\n",
      " 4   label       745 non-null    object\n",
      " 5   label_map   745 non-null    int64 \n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 35.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker1</th>\n",
       "      <th>statement1</th>\n",
       "      <th>speaker2</th>\n",
       "      <th>statement2</th>\n",
       "      <th>label</th>\n",
       "      <th>label_map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vice President Joe Biden</td>\n",
       "      <td>How you doing, man?</td>\n",
       "      <td>President Donald J. Trump</td>\n",
       "      <td>How are you doing?</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vice President Joe Biden</td>\n",
       "      <td>How you doing, man?</td>\n",
       "      <td>President Donald J. Trump</td>\n",
       "      <td>Thank you very much, Chris. I will tell you ve...</td>\n",
       "      <td>Counterargument</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vice President Joe Biden</td>\n",
       "      <td>Iâ€™m well.</td>\n",
       "      <td>President Donald J. Trump</td>\n",
       "      <td>How are you doing?</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vice President Joe Biden</td>\n",
       "      <td>Iâ€™m well.</td>\n",
       "      <td>President Donald J. Trump</td>\n",
       "      <td>Thank you very much, Chris. I will tell you ve...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vice President Joe Biden</td>\n",
       "      <td>Iâ€™m well.</td>\n",
       "      <td>President Donald J. Trump</td>\n",
       "      <td>And we won the election and therefore we have ...</td>\n",
       "      <td>Counterargument</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   speaker1           statement1                   speaker2  \\\n",
       "0  Vice President Joe Biden  How you doing, man?  President Donald J. Trump   \n",
       "1  Vice President Joe Biden  How you doing, man?  President Donald J. Trump   \n",
       "2  Vice President Joe Biden            Iâ€™m well.  President Donald J. Trump   \n",
       "3  Vice President Joe Biden            Iâ€™m well.  President Donald J. Trump   \n",
       "4  Vice President Joe Biden            Iâ€™m well.  President Donald J. Trump   \n",
       "\n",
       "                                          statement2            label  \\\n",
       "0                                 How are you doing?          Neutral   \n",
       "1  Thank you very much, Chris. I will tell you ve...  Counterargument   \n",
       "2                                 How are you doing?          Neutral   \n",
       "3  Thank you very much, Chris. I will tell you ve...          Neutral   \n",
       "4  And we won the election and therefore we have ...  Counterargument   \n",
       "\n",
       "   label_map  \n",
       "0          0  \n",
       "1          1  \n",
       "2          0  \n",
       "3          0  \n",
       "4          1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 416 entries, 0 to 415\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   speaker1    416 non-null    object\n",
      " 1   statement1  416 non-null    object\n",
      " 2   speaker2    416 non-null    object\n",
      " 3   statement2  416 non-null    object\n",
      " 4   label       416 non-null    object\n",
      " 5   label_map   416 non-null    int64 \n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 19.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker1</th>\n",
       "      <th>statement1</th>\n",
       "      <th>speaker2</th>\n",
       "      <th>statement2</th>\n",
       "      <th>label</th>\n",
       "      <th>label_map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Savannah Guthrie</td>\n",
       "      <td>Itâ€™s nothing but noise. What? Okay. All right,...</td>\n",
       "      <td>President Trump</td>\n",
       "      <td>Iâ€™m feeling great, I donâ€™t know about you. How...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Savannah Guthrie</td>\n",
       "      <td>Itâ€™s nothing but noise. What? Okay. All right,...</td>\n",
       "      <td>President Trump</td>\n",
       "      <td>Itâ€™s great to be back in my home state, Florid...</td>\n",
       "      <td>Counterargument</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Savannah Guthrie</td>\n",
       "      <td>Tonight, Donald Trump in the arena. His first ...</td>\n",
       "      <td>President Trump</td>\n",
       "      <td>Iâ€™m feeling great, I donâ€™t know about you. How...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Savannah Guthrie</td>\n",
       "      <td>Tonight, Donald Trump in the arena. His first ...</td>\n",
       "      <td>President Trump</td>\n",
       "      <td>Itâ€™s great to be back in my home state, Florid...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Savannah Guthrie</td>\n",
       "      <td>Tonight, Donald Trump in the arena. His first ...</td>\n",
       "      <td>President Trump</td>\n",
       "      <td>My goal is to fight for you and fight for your...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           speaker1                                         statement1  \\\n",
       "0  Savannah Guthrie  Itâ€™s nothing but noise. What? Okay. All right,...   \n",
       "1  Savannah Guthrie  Itâ€™s nothing but noise. What? Okay. All right,...   \n",
       "2  Savannah Guthrie  Tonight, Donald Trump in the arena. His first ...   \n",
       "3  Savannah Guthrie  Tonight, Donald Trump in the arena. His first ...   \n",
       "4  Savannah Guthrie  Tonight, Donald Trump in the arena. His first ...   \n",
       "\n",
       "          speaker2                                         statement2  \\\n",
       "0  President Trump  Iâ€™m feeling great, I donâ€™t know about you. How...   \n",
       "1  President Trump  Itâ€™s great to be back in my home state, Florid...   \n",
       "2  President Trump  Iâ€™m feeling great, I donâ€™t know about you. How...   \n",
       "3  President Trump  Itâ€™s great to be back in my home state, Florid...   \n",
       "4  President Trump  My goal is to fight for you and fight for your...   \n",
       "\n",
       "             label  label_map  \n",
       "0          Neutral          0  \n",
       "1  Counterargument          1  \n",
       "2          Neutral          0  \n",
       "3          Neutral          0  \n",
       "4          Neutral          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the labels\n",
    "label2id = {\"Neutral\": 0, \"Counterargument\": 1, \"Restatement\": 2}\n",
    "id2label = {v: k for k, v in label2id.items()}  # Reverse mapping\n",
    "\n",
    "# Load datasets for training\n",
    "df_agrument_1=pd.read_csv(os.path.join('../Datasets','us_debates','agrument','1st_presidential_agrument.csv'))\n",
    "# Only one speaker\n",
    "df_agrument_2=pd.read_csv(os.path.join('../Datasets','us_debates','agrument','trump_town_hall_agrument.csv'))\n",
    "\n",
    "# Map the labels\n",
    "df_agrument_1[\"label_map\"]=df_agrument_1[\"label\"].map(label2id)\n",
    "df_agrument_2[\"label_map\"]=df_agrument_2[\"label\"].map(label2id)\n",
    "\n",
    "# Print some dataset information\n",
    "df_agrument_1.info()\n",
    "df_agrument_1.head()\n",
    "df_agrument_2.info()\n",
    "df_agrument_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker1</th>\n",
       "      <th>statement1</th>\n",
       "      <th>speaker2</th>\n",
       "      <th>statement2</th>\n",
       "      <th>label</th>\n",
       "      <th>label_map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vice President Joe Biden</td>\n",
       "      <td>How you doing, man?</td>\n",
       "      <td>President Donald J. Trump</td>\n",
       "      <td>How are you doing?</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vice President Joe Biden</td>\n",
       "      <td>How you doing, man?</td>\n",
       "      <td>President Donald J. Trump</td>\n",
       "      <td>Thank you very much, Chris. I will tell you ve...</td>\n",
       "      <td>Counterargument</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vice President Joe Biden</td>\n",
       "      <td>Iâ€™m well.</td>\n",
       "      <td>President Donald J. Trump</td>\n",
       "      <td>How are you doing?</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vice President Joe Biden</td>\n",
       "      <td>Iâ€™m well.</td>\n",
       "      <td>President Donald J. Trump</td>\n",
       "      <td>Thank you very much, Chris. I will tell you ve...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vice President Joe Biden</td>\n",
       "      <td>Iâ€™m well.</td>\n",
       "      <td>President Donald J. Trump</td>\n",
       "      <td>And we won the election and therefore we have ...</td>\n",
       "      <td>Counterargument</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Vice President Joe Biden</td>\n",
       "      <td>Well, first of all, thank you for doing this a...</td>\n",
       "      <td>President Donald J. Trump</td>\n",
       "      <td>Thank you very much, Chris. I will tell you ve...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vice President Joe Biden</td>\n",
       "      <td>Well, first of all, thank you for doing this a...</td>\n",
       "      <td>President Donald J. Trump</td>\n",
       "      <td>And we won the election and therefore we have ...</td>\n",
       "      <td>Counterargument</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Vice President Joe Biden</td>\n",
       "      <td>Well, first of all, thank you for doing this a...</td>\n",
       "      <td>President Donald J. Trump</td>\n",
       "      <td>Thank you, Joe.</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vice President Joe Biden</td>\n",
       "      <td>The American people have a right to have a say...</td>\n",
       "      <td>President Donald J. Trump</td>\n",
       "      <td>And we won the election and therefore we have ...</td>\n",
       "      <td>Counterargument</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vice President Joe Biden</td>\n",
       "      <td>The American people have a right to have a say...</td>\n",
       "      <td>President Donald J. Trump</td>\n",
       "      <td>Thank you, Joe.</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   speaker1  \\\n",
       "0  Vice President Joe Biden   \n",
       "1  Vice President Joe Biden   \n",
       "2  Vice President Joe Biden   \n",
       "3  Vice President Joe Biden   \n",
       "4  Vice President Joe Biden   \n",
       "5  Vice President Joe Biden   \n",
       "6  Vice President Joe Biden   \n",
       "7  Vice President Joe Biden   \n",
       "8  Vice President Joe Biden   \n",
       "9  Vice President Joe Biden   \n",
       "\n",
       "                                          statement1  \\\n",
       "0                                How you doing, man?   \n",
       "1                                How you doing, man?   \n",
       "2                                          Iâ€™m well.   \n",
       "3                                          Iâ€™m well.   \n",
       "4                                          Iâ€™m well.   \n",
       "5  Well, first of all, thank you for doing this a...   \n",
       "6  Well, first of all, thank you for doing this a...   \n",
       "7  Well, first of all, thank you for doing this a...   \n",
       "8  The American people have a right to have a say...   \n",
       "9  The American people have a right to have a say...   \n",
       "\n",
       "                    speaker2  \\\n",
       "0  President Donald J. Trump   \n",
       "1  President Donald J. Trump   \n",
       "2  President Donald J. Trump   \n",
       "3  President Donald J. Trump   \n",
       "4  President Donald J. Trump   \n",
       "5  President Donald J. Trump   \n",
       "6  President Donald J. Trump   \n",
       "7  President Donald J. Trump   \n",
       "8  President Donald J. Trump   \n",
       "9  President Donald J. Trump   \n",
       "\n",
       "                                          statement2            label  \\\n",
       "0                                 How are you doing?          Neutral   \n",
       "1  Thank you very much, Chris. I will tell you ve...  Counterargument   \n",
       "2                                 How are you doing?          Neutral   \n",
       "3  Thank you very much, Chris. I will tell you ve...          Neutral   \n",
       "4  And we won the election and therefore we have ...  Counterargument   \n",
       "5  Thank you very much, Chris. I will tell you ve...          Neutral   \n",
       "6  And we won the election and therefore we have ...  Counterargument   \n",
       "7                                    Thank you, Joe.          Neutral   \n",
       "8  And we won the election and therefore we have ...  Counterargument   \n",
       "9                                    Thank you, Joe.          Neutral   \n",
       "\n",
       "   label_map  \n",
       "0          0  \n",
       "1          1  \n",
       "2          0  \n",
       "3          0  \n",
       "4          1  \n",
       "5          0  \n",
       "6          1  \n",
       "7          0  \n",
       "8          1  \n",
       "9          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1161 entries, 0 to 415\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   speaker1    1161 non-null   object\n",
      " 1   statement1  1161 non-null   object\n",
      " 2   speaker2    1161 non-null   object\n",
      " 3   statement2  1161 non-null   object\n",
      " 4   label       1161 non-null   object\n",
      " 5   label_map   1161 non-null   int64 \n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 63.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Concat the 2 early datasets\n",
    "df_trainer_final = pd.concat([df_agrument_1, df_agrument_2])\n",
    "df_trainer_final.head(10)\n",
    "df_trainer_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing\n",
    "We decided to use `distilbert-base-uncased` model with the following train hyperparamenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define our models hyperparameters\n",
    "bert_model_name = 'distilbert-base-uncased' # smaller bert model\n",
    "num_classes = 6\n",
    "max_length = 128\n",
    "batch_size = 8\n",
    "num_epochs = 10\n",
    "learning_rate = 2e-5\n",
    "warmup_steps=500  # number of warmup steps for learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    report = classification_report(labels, predictions, output_dict=True)\n",
    "    \n",
    "    # Make last report and last accuracy a global variable\n",
    "    logger.info(\"\\nðŸ“Š Classification Report:\\n%s\", classification_report(labels, predictions, digits=4))\n",
    "    logger.info(f\"Validation Accuracy: {report[\"accuracy\"]:.4f}\")\n",
    "\n",
    "    classification_report_metrics = {\n",
    "        \"accuracy\": report[\"accuracy\"],\n",
    "        \"precision\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"recall\": report[\"weighted avg\"][\"recall\"],\n",
    "        \"f1\": report[\"weighted avg\"][\"f1-score\"],\n",
    "    }\n",
    "    return classification_report_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"statement1\"], examples[\"statement2\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "def train_agrument_clasifier(model, statement1_train_list: list, statement2_train_list: list, labels_list: list, tokenizer):\n",
    "\n",
    "    x = list(zip(statement1_train_list, statement2_train_list))\n",
    "    y = labels_list\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.35, stratify=y)\n",
    "\n",
    "    # Do a split with stratify to preserve class distribution\n",
    "    train_data = Dataset.from_dict({\n",
    "        'statement1': [t[0] for t in x_train],\n",
    "        'statement2': [t[1] for t in x_train],\n",
    "        'label': [int(label) for label in y_train]\n",
    "    })\n",
    "\n",
    "    test_data = Dataset.from_dict({\n",
    "        'statement1': [t[0] for t in x_test],\n",
    "        'statement2': [t[1] for t in x_test],\n",
    "        'label': [int(label) for label in y_test]\n",
    "    })\n",
    "\n",
    "    train_data = train_data.map(tokenize_function, batched=True)\n",
    "    test_data = test_data.map(tokenize_function, batched=True)\n",
    "\n",
    "    # Remove original text columns (keep only tokenized inputs)\n",
    "    train_data = train_data.remove_columns([\"statement1\", \"statement2\"])\n",
    "    test_data = test_data.remove_columns([\"statement1\", \"statement2\"])\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        num_train_epochs=num_epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        warmup_steps=warmup_steps,\n",
    "        save_total_limit=2,  # limit the total amount of checkpoints, delete the older checkpoints\n",
    "        eval_steps=100, # Perform evaluation every 100 steps\n",
    "        save_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        metric_for_best_model=\"precision\",  # Metric to use for selecting the best model\n",
    "        greater_is_better=True,  # Whether a higher value of the metric is better\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_data,  # training data\n",
    "        eval_dataset=test_data,  # evaluation data\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.save_model(\"../models/distilbert_agrument_classifier\")\n",
    "    tokenizer.save_pretrained(\"../models/distilbert_agrument_classifier\")\n",
    "\n",
    "    # Reload with new model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"../models/distilbert_agrument_classifier\").to(device)\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"../models/distilbert_agrument_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 754/754 [00:00<00:00, 1116.97 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 407/407 [00:00<00:00, 1157.14 examples/s]\n",
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 500/950 [03:13<02:49,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.592, 'grad_norm': 19.568687438964844, 'learning_rate': 2e-05, 'epoch': 5.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 950/950 [06:16<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 376.9641, 'train_samples_per_second': 20.002, 'train_steps_per_second': 2.52, 'train_loss': 0.4909568224455181, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "# Load default model\n",
    "config = BertConfig.from_pretrained(bert_model_name, num_labels=len(label2id), label2id=label2id, id2label=id2label)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(bert_model_name, config=config).to(device)\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "\n",
    "# Training\n",
    "statement1_train_list=df_trainer_final[\"statement1\"].to_list()\n",
    "statement2_train_list=df_trainer_final[\"statement2\"].to_list()\n",
    "labels_list=df_trainer_final[\"label_map\"].to_list()\n",
    "\n",
    "train_agrument_clasifier(model, statement1_train_list, statement2_train_list, labels_list, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate models perfomance\n",
    "To evaluate the model we gonna give some agrument pre classified by llama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification is Counterargument\n",
      "Classification is Counterargument\n",
      "Classification is Neutral\n"
     ]
    }
   ],
   "source": [
    "# Function to test the sentiment of a text\n",
    "nli_model = pipeline(\"text-classification\", model=\"../models/distilbert_agrument_classifier\", device=device)\n",
    "\n",
    "def test_model(statement1, statement2, model, tokenizer):\n",
    "    input_text=f\"{statement1} </s></s> {statement2}\"\n",
    "    model_result=model(input_text, truncation=True)\n",
    "    print(f\"Classification is {model_result[0]['label']}\")\n",
    "\n",
    "# Test sentiment prediction\n",
    "test_model(\"The deal is that itâ€™s going to wipe out pre-existing conditions. And, by the way, the 200,000 people that have died on his watch, how many of those have survived? Well, thereâ€™s seven million people that contracted COVID.\"\n",
    "           ,\"And if you were here, it wouldnâ€™t be 200, it would be two million people because you were very late on the draw. You didnâ€™t want me to ban China, which was heavily infected. You didnâ€™t want me to ban Europe\", \n",
    "           nli_model, tokenizer) # Counterargument\n",
    "test_model(\"People want to be safe.\",\"Those states are not doing well that are shut down right now.\", nli_model, tokenizer) # Counterargument\n",
    "test_model(\"People want to be safe.\", \"Because itâ€™s a political thing.\", nli_model, tokenizer) # Neutral"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
